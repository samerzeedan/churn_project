{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17416164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samer\\churn_project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.20.0\n",
      "Keras: 3.12.0\n",
      "Optuna: 4.6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, BatchNormalization, Conv1D, MaxPooling1D,\n",
    "    Flatten, SimpleRNN, LSTM, MultiHeadAttention, LayerNormalization,\n",
    "    GlobalAveragePooling1D\n",
    ")\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Keras:\", tf.keras.__version__)\n",
    "print(\"Optuna:\", optuna.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3605c3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (5634, 26)\n",
      "Test: (1409, 26)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"processed_churn.csv\")\n",
    "\n",
    "X = df.drop(columns=[\"Churn\"])\n",
    "y = df[\"Churn\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "seq_len   = input_dim\n",
    "\n",
    "X_train_seq = np.expand_dims(X_train_scaled, axis=-1)\n",
    "X_test_seq  = np.expand_dims(X_test_scaled, axis=-1)\n",
    "\n",
    "print(\"Train:\", X_train_scaled.shape)\n",
    "print(\"Test:\", X_test_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5882dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dl_model(trial, model_type, input_dim, seq_len):\n",
    "    lr      = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    l2_reg  = trial.suggest_float(\"l2_reg\", 1e-6, 1e-3, log=True)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    reg     = regularizers.l2(l2_reg)\n",
    "\n",
    "    # =========================\n",
    "    # MLP\n",
    "    # =========================\n",
    "    if model_type == \"mlp\":\n",
    "        u1 = trial.suggest_int(\"mlp_u1\", 64, 256, step=32)\n",
    "        u2 = trial.suggest_int(\"mlp_u2\", 32, 128, step=32)\n",
    "\n",
    "        model = Sequential([\n",
    "            Dense(u1, activation=\"relu\", kernel_regularizer=reg, input_dim=input_dim),\n",
    "            BatchNormalization(),\n",
    "            Dropout(dropout),\n",
    "\n",
    "            Dense(u2, activation=\"relu\", kernel_regularizer=reg),\n",
    "            BatchNormalization(),\n",
    "            Dropout(dropout),\n",
    "\n",
    "            Dense(1, activation=\"sigmoid\")\n",
    "        ])\n",
    "\n",
    "    # =========================\n",
    "    # CNN 1D\n",
    "    # =========================\n",
    "    elif model_type == \"cnn\":\n",
    "        f1 = trial.suggest_int(\"cnn_f1\", 32, 128, step=32)\n",
    "        f2 = trial.suggest_int(\"cnn_f2\", 16, 64, step=16)\n",
    "        k  = trial.suggest_int(\"cnn_k\", 2, 5)\n",
    "\n",
    "        inputs = Input(shape=(seq_len, 1))\n",
    "        x = Conv1D(f1, k, activation=\"relu\", kernel_regularizer=reg)(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling1D(2)(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "\n",
    "        x = Conv1D(f2, k, activation=\"relu\", kernel_regularizer=reg)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling1D(2)(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(64, activation=\"relu\", kernel_regularizer=reg)(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "        model = Model(inputs, outputs)\n",
    "\n",
    "    # =========================\n",
    "    # RNN\n",
    "    # =========================\n",
    "    elif model_type == \"rnn\":\n",
    "        units = trial.suggest_int(\"rnn_units\", 32, 128, step=32)\n",
    "\n",
    "        model = Sequential([\n",
    "            SimpleRNN(units, input_shape=(seq_len,1),\n",
    "                      kernel_regularizer=reg, recurrent_regularizer=reg),\n",
    "            Dropout(dropout),\n",
    "            Dense(32, activation=\"relu\", kernel_regularizer=reg),\n",
    "            BatchNormalization(),\n",
    "            Dense(1, activation=\"sigmoid\")\n",
    "        ])\n",
    "\n",
    "    # =========================\n",
    "    # LSTM\n",
    "    # =========================\n",
    "    elif model_type == \"lstm\":\n",
    "        units = trial.suggest_int(\"lstm_units\", 32, 128, step=32)\n",
    "\n",
    "        model = Sequential([\n",
    "            LSTM(units, input_shape=(seq_len,1),\n",
    "                 kernel_regularizer=reg, recurrent_regularizer=reg),\n",
    "            Dropout(dropout),\n",
    "            Dense(32, activation=\"relu\", kernel_regularizer=reg),\n",
    "            BatchNormalization(),\n",
    "            Dense(1, activation=\"sigmoid\")\n",
    "        ])\n",
    "\n",
    "    # =========================\n",
    "    # Transformer Encoder\n",
    "    # =========================\n",
    "    elif model_type == \"transformer\":\n",
    "        d_model = trial.suggest_int(\"t_dmodel\", 32, 96, step=32)\n",
    "        heads   = trial.suggest_int(\"t_heads\", 2, 4)\n",
    "        ff_dim  = trial.suggest_int(\"t_ff\", 64, 256, step=64)\n",
    "\n",
    "        inputs = Input(shape=(seq_len,1))\n",
    "        x = Dense(d_model, kernel_regularizer=reg)(inputs)\n",
    "\n",
    "        att = MultiHeadAttention(num_heads=heads, key_dim=d_model//heads)(x, x)\n",
    "        x = LayerNormalization(epsilon=1e-6)(x + att)\n",
    "\n",
    "        ff = Dense(ff_dim, activation=\"relu\")(x)\n",
    "        ff = Dense(d_model)(ff)\n",
    "        x = LayerNormalization(epsilon=1e-6)(x + ff)\n",
    "\n",
    "        x = GlobalAveragePooling1D()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "\n",
    "        x = Dense(64, activation=\"relu\")(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "\n",
    "        outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "        model = Model(inputs, outputs)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type.\")\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ead02cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model_type = trial.suggest_categorical(\n",
    "        \"model_type\",\n",
    "        [\"mlp\", \"cnn\", \"rnn\", \"lstm\", \"transformer\"]\n",
    "    )\n",
    "\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_train_scaled, y_train,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_train\n",
    "    )\n",
    "\n",
    "    if model_type == \"mlp\":\n",
    "        X_tr_in = X_tr\n",
    "        X_val_in = X_val\n",
    "    else:\n",
    "        X_tr_in = np.expand_dims(X_tr, axis=-1)\n",
    "        X_val_in = np.expand_dims(X_val, axis=-1)\n",
    "\n",
    "    model = build_dl_model(trial, model_type, input_dim, seq_len)\n",
    "\n",
    "    early = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_tr_in, y_tr,\n",
    "        validation_data=(X_val_in, y_val),\n",
    "        epochs=15,\n",
    "        batch_size=trial.suggest_categorical(\"batch\", [32,64,128]),\n",
    "        verbose=0,\n",
    "        callbacks=[early]\n",
    "    )\n",
    "\n",
    "    # =====================\n",
    "    # TRAIN RESULT\n",
    "    # =====================\n",
    "    train_proba = model.predict(X_tr_in, verbose=0).flatten()\n",
    "    train_pred  = (train_proba >= 0.5).astype(int)\n",
    "\n",
    "    train_acc  = accuracy_score(y_tr, train_pred)\n",
    "    train_auc  = roc_auc_score(y_tr, train_proba)\n",
    "    train_loss = log_loss(y_tr, train_proba)\n",
    "\n",
    "    # =====================\n",
    "    # VALIDATION RESULT\n",
    "    # =====================\n",
    "    val_proba = model.predict(X_val_in, verbose=0).flatten()\n",
    "    val_pred  = (val_proba >= 0.5).astype(int)\n",
    "\n",
    "    val_acc  = accuracy_score(y_val, val_pred)\n",
    "    val_auc  = roc_auc_score(y_val, val_proba)\n",
    "    val_loss = log_loss(y_val, val_proba)\n",
    "\n",
    "    # save them\n",
    "    trial.set_user_attr(\"model_type\", model_type)\n",
    "    trial.set_user_attr(\"train_acc\", float(train_acc))\n",
    "    trial.set_user_attr(\"train_auc\", float(train_auc))\n",
    "    trial.set_user_attr(\"train_loss\", float(train_loss))\n",
    "    trial.set_user_attr(\"val_acc\", float(val_acc))\n",
    "    trial.set_user_attr(\"val_loss\", float(val_loss))\n",
    "\n",
    "    return val_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c25f0d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-06 21:20:43,611] A new study created in memory with name: no-name-2eb9c8b4-3d63-4703-97c8-76e0a60e9c0a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samer\\churn_project\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "[I 2025-12-06 21:20:59,768] Trial 0 finished with value: 0.8289628875640218 and parameters: {'model_type': 'lstm', 'lr': 0.001507423277447287, 'l2_reg': 1.945916438398404e-06, 'dropout': 0.13661754251554234, 'lstm_units': 32, 'batch': 32}. Best is trial 0 with value: 0.8289628875640218.\n",
      "[I 2025-12-06 21:21:04,329] Trial 1 finished with value: 0.8297343803014882 and parameters: {'model_type': 'cnn', 'lr': 0.0005884454493730873, 'l2_reg': 7.3723389208437366e-06, 'dropout': 0.2700734744217837, 'cnn_f1': 96, 'cnn_f2': 64, 'cnn_k': 3, 'batch': 128}. Best is trial 1 with value: 0.8297343803014882.\n",
      "c:\\Users\\samer\\churn_project\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "[I 2025-12-06 21:21:08,497] Trial 2 finished with value: 0.8343431405813259 and parameters: {'model_type': 'mlp', 'lr': 0.00010965498492198123, 'l2_reg': 0.0005113627253088087, 'dropout': 0.09768300898496399, 'mlp_u1': 64, 'mlp_u2': 32, 'batch': 128}. Best is trial 2 with value: 0.8343431405813259.\n",
      "[I 2025-12-06 21:21:12,814] Trial 3 finished with value: 0.8084355258268302 and parameters: {'model_type': 'cnn', 'lr': 0.0011469389031225033, 'l2_reg': 3.4875055152627507e-06, 'dropout': 0.3968426918757243, 'cnn_f1': 64, 'cnn_f2': 64, 'cnn_k': 3, 'batch': 64}. Best is trial 2 with value: 0.8343431405813259.\n",
      "[I 2025-12-06 21:21:30,507] Trial 4 finished with value: 0.8333575687072852 and parameters: {'model_type': 'cnn', 'lr': 0.00024153804525386515, 'l2_reg': 0.0004142379808497379, 'dropout': 0.10895696675498563, 'cnn_f1': 128, 'cnn_f2': 64, 'cnn_k': 5, 'batch': 64}. Best is trial 2 with value: 0.8343431405813259.\n",
      "c:\\Users\\samer\\churn_project\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "[I 2025-12-06 21:21:43,285] Trial 5 finished with value: 0.8308694036482316 and parameters: {'model_type': 'mlp', 'lr': 0.000164435487647402, 'l2_reg': 2.7580199623879215e-06, 'dropout': 0.03033945486454184, 'mlp_u1': 160, 'mlp_u2': 64, 'batch': 32}. Best is trial 2 with value: 0.8343431405813259.\n",
      "c:\\Users\\samer\\churn_project\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "[I 2025-12-06 21:22:04,360] Trial 6 finished with value: 0.8232796923723199 and parameters: {'model_type': 'lstm', 'lr': 0.0010057938674694993, 'l2_reg': 3.3803666898835647e-06, 'dropout': 0.14047355064301872, 'lstm_units': 128, 'batch': 128}. Best is trial 2 with value: 0.8343431405813259.\n",
      "[I 2025-12-06 21:22:13,647] Trial 7 finished with value: 0.8421752055967557 and parameters: {'model_type': 'cnn', 'lr': 0.00042275973141824485, 'l2_reg': 2.208110587350439e-06, 'dropout': 0.2909215120357102, 'cnn_f1': 96, 'cnn_f2': 16, 'cnn_k': 4, 'batch': 128}. Best is trial 7 with value: 0.8421752055967557.\n",
      "[I 2025-12-06 21:22:19,093] Trial 8 finished with value: 0.7432100560644983 and parameters: {'model_type': 'cnn', 'lr': 0.0001632923862407985, 'l2_reg': 4.368912058209207e-06, 'dropout': 0.3541594832872846, 'cnn_f1': 96, 'cnn_f2': 64, 'cnn_k': 3, 'batch': 128}. Best is trial 7 with value: 0.8421752055967557.\n",
      "[I 2025-12-06 21:22:23,923] Trial 9 finished with value: 0.7942255182330796 and parameters: {'model_type': 'cnn', 'lr': 0.0004203417992582792, 'l2_reg': 0.0004390703121204126, 'dropout': 0.03142103766725799, 'cnn_f1': 64, 'cnn_f2': 64, 'cnn_k': 3, 'batch': 128}. Best is trial 7 with value: 0.8421752055967557.\n",
      "c:\\Users\\samer\\churn_project\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "[I 2025-12-06 21:22:32,354] Trial 10 finished with value: 0.7957119545021247 and parameters: {'model_type': 'rnn', 'lr': 0.0031375070114380375, 'l2_reg': 3.219244714860329e-05, 'dropout': 0.25835269168731584, 'rnn_units': 128, 'batch': 32}. Best is trial 7 with value: 0.8421752055967557.\n",
      "c:\\Users\\samer\\churn_project\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "[I 2025-12-06 21:22:38,122] Trial 11 finished with value: 0.81950705249382 and parameters: {'model_type': 'mlp', 'lr': 0.0001020308529672306, 'l2_reg': 7.41180386785274e-05, 'dropout': 0.2234474930460083, 'mlp_u1': 64, 'mlp_u2': 32, 'batch': 128}. Best is trial 7 with value: 0.8421752055967557.\n",
      "[I 2025-12-06 21:22:47,647] Trial 12 finished with value: 0.6304145864637358 and parameters: {'model_type': 'transformer', 'lr': 0.00032339766823849027, 'l2_reg': 0.000958863214768719, 'dropout': 0.3028672555754257, 't_dmodel': 64, 't_heads': 3, 't_ff': 192, 'batch': 128}. Best is trial 7 with value: 0.8421752055967557.\n",
      "c:\\Users\\samer\\churn_project\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "[I 2025-12-06 21:22:55,785] Trial 13 finished with value: 0.8315924256377942 and parameters: {'model_type': 'mlp', 'lr': 0.00010372980677807849, 'l2_reg': 0.00010285221152220884, 'dropout': 0.18203104475455284, 'mlp_u1': 64, 'mlp_u2': 128, 'batch': 128}. Best is trial 7 with value: 0.8421752055967557.\n",
      "c:\\Users\\samer\\churn_project\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "[I 2025-12-06 21:23:00,619] Trial 14 finished with value: 0.8337453346905144 and parameters: {'model_type': 'rnn', 'lr': 0.0049822570225090046, 'l2_reg': 1.0497447773707184e-06, 'dropout': 0.084425934563669, 'rnn_units': 32, 'batch': 128}. Best is trial 7 with value: 0.8421752055967557.\n",
      "[I 2025-12-06 21:23:23,642] Trial 15 finished with value: 0.6854611991663032 and parameters: {'model_type': 'transformer', 'lr': 0.0005667275834567215, 'l2_reg': 1.0843785604967426e-05, 'dropout': 0.19678362938259095, 't_dmodel': 96, 't_heads': 2, 't_ff': 64, 'batch': 64}. Best is trial 7 with value: 0.8421752055967557.\n",
      "c:\\Users\\samer\\churn_project\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "[I 2025-12-06 21:23:31,021] Trial 16 finished with value: 0.8410038291890845 and parameters: {'model_type': 'mlp', 'lr': 0.00020101943223944257, 'l2_reg': 2.0119075739072957e-05, 'dropout': 0.30934955434005723, 'mlp_u1': 256, 'mlp_u2': 32, 'batch': 128}. Best is trial 7 with value: 0.8421752055967557.\n",
      "c:\\Users\\samer\\churn_project\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "[I 2025-12-06 21:23:36,805] Trial 17 finished with value: 0.8425548931220008 and parameters: {'model_type': 'mlp', 'lr': 0.00023605869935066663, 'l2_reg': 1.386098417117906e-05, 'dropout': 0.3207600631420176, 'mlp_u1': 256, 'mlp_u2': 96, 'batch': 128}. Best is trial 17 with value: 0.8425548931220008.\n",
      "c:\\Users\\samer\\churn_project\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "[I 2025-12-06 21:23:46,394] Trial 18 finished with value: 0.8482704021456383 and parameters: {'model_type': 'rnn', 'lr': 0.0003557479919953826, 'l2_reg': 1.581789284287251e-05, 'dropout': 0.3484681157034343, 'rnn_units': 128, 'batch': 64}. Best is trial 18 with value: 0.8482704021456383.\n",
      "c:\\Users\\samer\\churn_project\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "[I 2025-12-06 21:23:58,074] Trial 19 finished with value: 0.8468526327694571 and parameters: {'model_type': 'rnn', 'lr': 0.0002929102224600778, 'l2_reg': 4.005909741558873e-05, 'dropout': 0.36895039583970474, 'rnn_units': 128, 'batch': 64}. Best is trial 18 with value: 0.8482704021456383.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 0.8482704021456383\n",
      "Best Params: {'model_type': 'rnn', 'lr': 0.0003557479919953826, 'l2_reg': 1.581789284287251e-05, 'dropout': 0.3484681157034343, 'rnn_units': 128, 'batch': 64}\n",
      "Best Model: rnn\n"
     ]
    }
   ],
   "source": [
    "N_TRIALS = 20\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "print(\"Best AUC:\", study.best_value)\n",
    "print(\"Best Params:\", study.best_trial.params)\n",
    "print(\"Best Model:\", study.best_trial.user_attrs[\"model_type\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06292e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Deep Learning Comparison Table ===\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn</td>\n",
       "      <td>0.795207</td>\n",
       "      <td>0.802130</td>\n",
       "      <td>0.845896</td>\n",
       "      <td>0.842175</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.439106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lstm</td>\n",
       "      <td>0.799201</td>\n",
       "      <td>0.800355</td>\n",
       "      <td>0.838617</td>\n",
       "      <td>0.828963</td>\n",
       "      <td>0.425759</td>\n",
       "      <td>0.434288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.815620</td>\n",
       "      <td>0.813665</td>\n",
       "      <td>0.868553</td>\n",
       "      <td>0.842555</td>\n",
       "      <td>0.403816</td>\n",
       "      <td>0.427278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rnn</td>\n",
       "      <td>0.797204</td>\n",
       "      <td>0.801242</td>\n",
       "      <td>0.853521</td>\n",
       "      <td>0.848270</td>\n",
       "      <td>0.427354</td>\n",
       "      <td>0.430395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transformer</td>\n",
       "      <td>0.745729</td>\n",
       "      <td>0.737356</td>\n",
       "      <td>0.693464</td>\n",
       "      <td>0.685461</td>\n",
       "      <td>0.533900</td>\n",
       "      <td>0.539155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_type  train_acc   val_acc  train_auc   val_auc  train_loss  val_loss\n",
       "0          cnn   0.795207  0.802130   0.845896  0.842175    0.435847  0.439106\n",
       "1         lstm   0.799201  0.800355   0.838617  0.828963    0.425759  0.434288\n",
       "2          mlp   0.815620  0.813665   0.868553  0.842555    0.403816  0.427278\n",
       "3          rnn   0.797204  0.801242   0.853521  0.848270    0.427354  0.430395\n",
       "4  transformer   0.745729  0.737356   0.693464  0.685461    0.533900  0.539155"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = []\n",
    "for t in study.trials:\n",
    "    if t.state.name != \"COMPLETE\":\n",
    "        continue\n",
    "\n",
    "    rows.append({\n",
    "        \"model_type\": t.user_attrs[\"model_type\"],\n",
    "        \"train_acc\":  t.user_attrs[\"train_acc\"],\n",
    "        \"val_acc\":    t.user_attrs[\"val_acc\"],\n",
    "        \"train_auc\":  t.user_attrs[\"train_auc\"],\n",
    "        \"val_auc\":    t.value,\n",
    "        \"train_loss\": t.user_attrs[\"train_loss\"],\n",
    "        \"val_loss\":   t.user_attrs[\"val_loss\"]\n",
    "    })\n",
    "\n",
    "df_dl = pd.DataFrame(rows)\n",
    "\n",
    "best_per_model = (\n",
    "    df_dl.sort_values(\"val_auc\", ascending=False)\n",
    "         .groupby(\"model_type\")\n",
    "         .first()\n",
    "         .reset_index()\n",
    ")\n",
    "\n",
    "print(\"\\n=== Final Deep Learning Comparison Table ===\\n\")\n",
    "display(best_per_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32bed3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = 0.0005694339909914094\n",
    "best_l2 = 4.982806891517478e-06\n",
    "best_dropout = 0.3179818384226337\n",
    "best_u1 = 256\n",
    "best_u2 = 128\n",
    "best_batch = 32\n",
    "\n",
    "reg = tf.keras.regularizers.l2(best_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45d8f448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_best_mlp():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(best_u1, activation=\"relu\", kernel_regularizer=reg, input_dim=input_dim),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(best_dropout),\n",
    "\n",
    "        tf.keras.layers.Dense(best_u2, activation=\"relu\", kernel_regularizer=reg),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(best_dropout),\n",
    "\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=best_lr)\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=optimizer,\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75b1747e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samer\\churn_project\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,912</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m6,912\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,473</span> (162.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m41,473\u001b[0m (162.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,705</span> (159.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,705\u001b[0m (159.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_mlp_model = build_best_mlp()\n",
    "best_mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "394a8cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=4,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9750a14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7124 - loss: 0.6189 - val_accuracy: 0.7391 - val_loss: 0.5035\n",
      "Epoch 2/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7659 - loss: 0.5111 - val_accuracy: 0.7737 - val_loss: 0.4699\n",
      "Epoch 3/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7797 - loss: 0.4774 - val_accuracy: 0.7959 - val_loss: 0.4422\n",
      "Epoch 4/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7854 - loss: 0.4620 - val_accuracy: 0.7933 - val_loss: 0.4477\n",
      "Epoch 5/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7945 - loss: 0.4480 - val_accuracy: 0.7870 - val_loss: 0.4522\n",
      "Epoch 6/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7934 - loss: 0.4416 - val_accuracy: 0.7773 - val_loss: 0.4533\n",
      "Epoch 7/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7923 - loss: 0.4309 - val_accuracy: 0.7799 - val_loss: 0.4503\n"
     ]
    }
   ],
   "source": [
    "history = best_mlp_model.fit(\n",
    "    X_train_scaled, \n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    batch_size=best_batch,\n",
    "    verbose=1,\n",
    "    callbacks=[early]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f105702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "test_proba = best_mlp_model.predict(X_test_scaled).flatten()\n",
    "test_pred = (test_proba >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aeed1da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== FINAL MLP TEST RESULTS =====\n",
      "Test Accuracy: 0.7934705464868701\n",
      "Test AUC: 0.8429900023250407\n",
      "Test Log Loss: 0.4226578774074473\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87      1035\n",
      "           1       0.66      0.45      0.54       374\n",
      "\n",
      "    accuracy                           0.79      1409\n",
      "   macro avg       0.74      0.68      0.70      1409\n",
      "weighted avg       0.78      0.79      0.78      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss, classification_report\n",
    "\n",
    "test_acc  = accuracy_score(y_test, test_pred)\n",
    "test_auc  = roc_auc_score(y_test, test_proba)\n",
    "test_loss = log_loss(y_test, test_proba)\n",
    "\n",
    "print(\"===== FINAL MLP TEST RESULTS =====\")\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(\"Test Log Loss:\", test_loss)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "298dcc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved as best_deep_learning_model.h5\n"
     ]
    }
   ],
   "source": [
    "best_mlp_model.save(\"best_deep_learning_model.h5\")\n",
    "print(\"\\nModel saved as best_deep_learning_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f519f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved as scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"Scaler saved as scaler.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e037ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
